{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "DataOrchestration-ADF"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/Lakehouse Pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Lakehouse Pipeline",
				"activities": [
					{
						"name": "dataflow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "DF_DeltaLake",
								"type": "DataFlowReference"
							},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"folder": {
					"name": "LH"
				},
				"annotations": [],
				"lastPublishTime": "2020-11-27T01:35:10Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/MDW_Dim_Product_Pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "MDW_Dim_Product",
				"activities": [
					{
						"name": "Copy data Source to Staging",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderQuery": "select * from dbo.product_table where Sync_Flag=0;",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"sink": {
								"type": "AzureSqlSink",
								"preCopyScript": "truncate table dbo.product_dim_stg",
								"disableMetricsCollection": false
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": "product_id",
											"type": "Int32",
											"physicalType": "int"
										},
										"sink": {
											"name": "product_id",
											"type": "Int32",
											"physicalType": "int"
										}
									},
									{
										"source": {
											"name": "product_name",
											"type": "String",
											"physicalType": "varchar"
										},
										"sink": {
											"name": "product_name",
											"type": "String",
											"physicalType": "varchar"
										}
									},
									{
										"source": {
											"name": "unit_price",
											"type": "Double",
											"physicalType": "float"
										},
										"sink": {
											"name": "unit_price",
											"type": "Double",
											"physicalType": "float"
										}
									},
									{
										"source": {
											"name": "product_desc",
											"type": "String",
											"physicalType": "varchar"
										},
										"sink": {
											"name": "product_desc",
											"type": "String",
											"physicalType": "varchar"
										}
									},
									{
										"source": {
											"name": "eligible_promotion",
											"type": "Int32",
											"physicalType": "int"
										},
										"sink": {
											"name": "eligible_promotion",
											"type": "Int32",
											"physicalType": "int"
										}
									}
								],
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "SourceProductTable",
								"type": "DatasetReference"
							}
						],
						"outputs": [
							{
								"referenceName": "TargetProductStaging",
								"type": "DatasetReference"
							}
						]
					}
				],
				"folder": {
					"name": "MDW"
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Product SCD2 Pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Product SCD2 Pipeline",
				"activities": [
					{
						"name": "Copy data Source to Staging",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderQuery": "select * from dbo.product_table where Sync_Flag=0;",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"sink": {
								"type": "AzureSqlSink",
								"preCopyScript": "truncate table dbo.product_dim_stg",
								"disableMetricsCollection": false
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": "product_id",
											"type": "Int32",
											"physicalType": "int"
										},
										"sink": {
											"name": "product_id",
											"type": "Int32",
											"physicalType": "int"
										}
									},
									{
										"source": {
											"name": "product_name",
											"type": "String",
											"physicalType": "varchar"
										},
										"sink": {
											"name": "product_name",
											"type": "String",
											"physicalType": "varchar"
										}
									},
									{
										"source": {
											"name": "unit_price",
											"type": "Double",
											"physicalType": "float"
										},
										"sink": {
											"name": "unit_price",
											"type": "Double",
											"physicalType": "float"
										}
									},
									{
										"source": {
											"name": "product_desc",
											"type": "String",
											"physicalType": "varchar"
										},
										"sink": {
											"name": "product_desc",
											"type": "String",
											"physicalType": "varchar"
										}
									},
									{
										"source": {
											"name": "eligible_promotion",
											"type": "Int32",
											"physicalType": "int"
										},
										"sink": {
											"name": "eligible_promotion",
											"type": "Int32",
											"physicalType": "int"
										}
									}
								],
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "SourceProductTable",
								"type": "DatasetReference"
							}
						],
						"outputs": [
							{
								"referenceName": "TargetProductStaging",
								"type": "DatasetReference"
							}
						]
					},
					{
						"name": "scd2 dataflow",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Copy data Source to Staging",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "DF_Product_SCD2",
								"type": "DataFlowReference"
							},
							"staging": {
								"linkedService": {
									"referenceName": "AzureDataLakeStorage",
									"type": "LinkedServiceReference"
								},
								"folderPath": "sinkdata/SynapseStage"
							},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "Update Source Sync Flag",
						"type": "Lookup",
						"dependsOn": [
							{
								"activity": "scd2 dataflow",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderQuery": {
									"value": "update dbo.product_table set Sync_Flag=1;\n\nselect getdate();",
									"type": "Expression"
								},
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "SourceProductTable",
								"type": "DatasetReference"
							},
							"firstRowOnly": false
						}
					}
				],
				"folder": {
					"name": "SCD"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/DF_Product_SCD2')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Transformation with Azure Databricks')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Run a simple Transformation job using Azure Databricks, with a single pane of glass monitoring from ADF.\n\nIn the template, we check for source dataset availability. Once it is available we copy it into a blob storage for staging using a Copy activity. The same storage is accessed from Databricks clusters while processing the data (Transformation). The output is stored in the same storage under 'output' folder. Various notebook properties are referenced as expressions using pipeline parameters, which lets you configure more generic and reusable pipelines.",
				"activities": [
					{
						"name": "Load Blob",
						"description": "Copy activity copies the actual files/ dataset to be processed by Databricks into a staging store. This storage should be accessible by the Azure Databricks cluster referenced in the next activity. ",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"wildcardFileName": "*"
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false,
							"dataIntegrationUnits": 0
						},
						"inputs": [
							{
								"referenceName": "SourceFilesDataset",
								"type": "DatasetReference"
							}
						],
						"outputs": [
							{
								"referenceName": "DestinationFilesDataset",
								"type": "DatasetReference"
							}
						]
					},
					{
						"name": "Transformation",
						"description": "Databricks Notebook activity does the processing of the data copied in the previous step (copy activity).  Please ensure you have added the databricks notebook (<a href='https://adflabstaging1.blob.core.windows.net/share/Transformations.html' target='_blank'>https://adflabstaging1.blob.core.windows.net/share/Transformations.html</a>) in the databricks work-space and referenced it in the notebook activity in ADF.",
						"type": "DatabricksNotebook",
						"dependsOn": [
							{
								"activity": "Load Blob",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebookPath": "/ADF-ADB/Transformations",
							"baseParameters": {
								"input": {
									"value": "@pipeline().parameters.inputPath",
									"type": "Expression"
								},
								"output": {
									"value": "@pipeline().parameters.outputPath",
									"type": "Expression"
								},
								"filename": {
									"value": "@pipeline().parameters.fileName",
									"type": "Expression"
								},
								"pipelineRunId": {
									"value": "@pipeline().RunId",
									"type": "Expression"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "AzureDatabricksLinkedService",
							"type": "LinkedServiceReference"
						}
					}
				],
				"parameters": {
					"inputPath": {
						"type": "String",
						"defaultValue": "/staged_sink"
					},
					"outputPath": {
						"type": "String",
						"defaultValue": "/processed_sink"
					},
					"fileName": {
						"type": "String",
						"defaultValue": "Product.csv"
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/SourceFilesDataset')]",
				"[concat(variables('factoryId'), '/datasets/DestinationFilesDataset')]",
				"[concat(variables('factoryId'), '/linkedServices/AzureDatabricksLinkedService')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DestinationFilesDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Connection to your destination Azure Blob Store.",
				"linkedServiceName": {
					"referenceName": "AzureBlobStorageLinkedServiceDest",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "staged_sink",
						"container": "sinkdata"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/SourceAvailabilityDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Dataset to check if '_success' flag/ file is available in source. If not, the activity fails, indicating that source dataset is not ready.\nContext: In Spark/ Hadoop environments, generally users leverage flags to identify if the data has been correctly written through the distributed compute engines. E.g. '_success' defines all nodes have successfully written the data.",
				"linkedServiceName": {
					"referenceName": "AzureBlobStorageLinkedService",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "_success",
						"folderPath": "source",
						"container": "data"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/SourceFilesDataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Connection to your source files in Azure Blob Store.",
				"linkedServiceName": {
					"referenceName": "AzureBlobStorageLinkedService",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "Product.csv",
						"folderPath": "source",
						"container": "data"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/AzureDatabricksLinkedService')]",
			"type": "Microsoft.DataFactory/factories/linkedServices",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"type": "AzureDatabricks",
				"typeProperties": {
					"domain": "https://adb-1037359774903558.18.azuredatabricks.net",
					"accessToken": {
						"type": "SecureString",
						"value": "**********"
					},
					"existingClusterId": "1127-001851-ended758"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DF_Product_SCD2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "DF_Product_SCD2",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "TargetProductStaging",
								"type": "DatasetReference"
							},
							"name": "sourceStaging"
						},
						{
							"dataset": {
								"referenceName": "DS_DIM_Product_SCD2_Synapse",
								"type": "DatasetReference"
							},
							"name": "sourceTarget"
						},
						{
							"dataset": {
								"referenceName": "DS_DIM_Product_SCD2_Synapse",
								"type": "DatasetReference"
							},
							"name": "MaxSurrogateKey"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DS_DIM_Product_SCD2_Synapse",
								"type": "DatasetReference"
							},
							"name": "UpdateSink"
						},
						{
							"dataset": {
								"referenceName": "DS_DIM_Product_SCD2_Synapse",
								"type": "DatasetReference"
							},
							"name": "InsertNewsink"
						},
						{
							"dataset": {
								"referenceName": "DS_DIM_Product_SCD2_Synapse",
								"type": "DatasetReference"
							},
							"name": "InsertExistingProduct"
						}
					],
					"transformations": [
						{
							"name": "ExistsForUpdate"
						},
						{
							"name": "ProductKeyAddedDateLookup"
						},
						{
							"name": "UpdatedDateDerivedColumn"
						},
						{
							"name": "UpdateAlterRow"
						},
						{
							"name": "InsertNewRecordExists"
						},
						{
							"name": "JoinForSurrogateKeyNew"
						},
						{
							"name": "DerivedColumns"
						},
						{
							"name": "SurrogateKeyCalculation"
						},
						{
							"name": "JoinforSurrogateKeyExisting"
						},
						{
							"name": "SurrogateKeyCalculationExisting"
						},
						{
							"name": "DerivedColumnExisting"
						}
					],
					"script": "source(output(\n\t\tproduct_id as integer,\n\t\tproduct_name as string,\n\t\tunit_price as double,\n\t\tproduct_desc as string,\n\t\teligible_promotion as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table') ~> sourceStaging\nsource(output(\n\t\tproduct_key as integer,\n\t\tproduct_id as integer,\n\t\tproduct_name as string,\n\t\tunit_price as double,\n\t\tproduct_desc as string,\n\t\teligible_promotion as integer,\n\t\tis_active as integer,\n\t\tstart_date as timestamp,\n\t\tend_date as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table',\n\tstaged: false) ~> sourceTarget\nsource(output(\n\t\tMaxSurrogateKey as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tquery: 'select isNull(max(product_key),0) as MaxSurrogateKey from dbo.product_dim',\n\tformat: 'query',\n\tstaged: false) ~> MaxSurrogateKey\nsourceStaging, sourceTarget exists(sourceStaging@product_id == sourceTarget@product_id,\n\tnegate:false,\n\tbroadcast: 'auto')~> ExistsForUpdate\nExistsForUpdate, sourceTarget lookup(sourceStaging@product_id == sourceTarget@product_id,\n\tmultiple: false,\n\tpickup: 'any',\n\tbroadcast: 'auto')~> ProductKeyAddedDateLookup\nProductKeyAddedDateLookup derive(updated_date = currentTimestamp(),\n\t\tis_active = 0) ~> UpdatedDateDerivedColumn\nUpdatedDateDerivedColumn alterRow(updateIf(true())) ~> UpdateAlterRow\nsourceStaging, sourceTarget exists(sourceStaging@product_id == sourceTarget@product_id,\n\tnegate:true,\n\tbroadcast: 'auto')~> InsertNewRecordExists\nInsertNewRecordExists, MaxSurrogateKey join(true(),\n\tjoinType:'cross',\n\tbroadcast: 'auto')~> JoinForSurrogateKeyNew\nSurrogateKeyCalculation derive(product_key = MaxSurrogateKey+s_key,\n\t\tadded_date = currentTimestamp()) ~> DerivedColumns\nJoinForSurrogateKeyNew keyGenerate(output(s_key as long),\n\tstartAt: 1L) ~> SurrogateKeyCalculation\nExistsForUpdate, MaxSurrogateKey join(true(),\n\tjoinType:'cross',\n\tbroadcast: 'auto')~> JoinforSurrogateKeyExisting\nJoinforSurrogateKeyExisting keyGenerate(output(s_key as long),\n\tstartAt: 1L) ~> SurrogateKeyCalculationExisting\nSurrogateKeyCalculationExisting derive(product_key = MaxSurrogateKey+s_key,\n\t\tadded_date = currentTimestamp()) ~> DerivedColumnExisting\nUpdateAlterRow sink(input(\n\t\tproduct_key as integer,\n\t\tproduct_id as integer,\n\t\tproduct_name as string,\n\t\tunit_price as double,\n\t\tproduct_desc as string,\n\t\teligible_promotion as integer,\n\t\tis_active as integer,\n\t\tstart_date as timestamp,\n\t\tend_date as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tdeletable:false,\n\tinsertable:false,\n\tupdateable:true,\n\tupsertable:false,\n\tkeys:['product_id'],\n\tformat: 'table',\n\tstaged: true,\n\tmapColumn(\n\t\tproduct_key,\n\t\tproduct_id = sourceStaging@product_id,\n\t\tis_active,\n\t\tend_date = updated_date\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> UpdateSink\nDerivedColumns sink(input(\n\t\tproduct_key as integer,\n\t\tproduct_id as integer,\n\t\tproduct_name as string,\n\t\tunit_price as double,\n\t\tproduct_desc as string,\n\t\teligible_promotion as integer,\n\t\tis_active as integer,\n\t\tstart_date as timestamp,\n\t\tend_date as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false,\n\tformat: 'table',\n\tstaged: true,\n\tmapColumn(\n\t\tproduct_key,\n\t\tproduct_id,\n\t\tproduct_name,\n\t\tunit_price,\n\t\tproduct_desc,\n\t\teligible_promotion,\n\t\tstart_date = added_date\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> InsertNewsink\nDerivedColumnExisting sink(input(\n\t\tproduct_key as integer,\n\t\tproduct_id as integer,\n\t\tproduct_name as string,\n\t\tunit_price as double,\n\t\tproduct_desc as string,\n\t\teligible_promotion as integer,\n\t\tis_active as integer,\n\t\tstart_date as timestamp,\n\t\tend_date as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false,\n\tformat: 'table',\n\tstaged: true,\n\tmapColumn(\n\t\tproduct_key,\n\t\tproduct_id,\n\t\tproduct_name,\n\t\tunit_price,\n\t\tproduct_desc,\n\t\teligible_promotion,\n\t\tstart_date = added_date\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> InsertExistingProduct"
				}
			},
			"dependsOn": []
		}
	]
}